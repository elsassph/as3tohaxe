-- Parse the tokens generated by Lexer

module ActionhaXe.Parser where

import ActionhaXe.Lexer
import ActionhaXe.Prim
import Text.Parsec
import Text.Parsec.Combinator
import Data.Map (Map)
import qualified Data.Map as Map

data BlockItem =  Tok        CToken
                | Block      CToken [BlockItem] CToken
                | ImportDecl CToken CToken Semi
    deriving (Show)

data Ast = Program Package AsState
    deriving (Show)

data Package = Package CToken (Maybe CToken) BlockItem
    deriving (Show)

program :: AsParser Ast
program = do{ x <- package; a <- getState; return $ Program x a}

package = do{ p <- kw "package"; i <- optionMaybe(ident); b <- block; return $ Package p i b }

importDecl = do{ k <- kw "import"; s <- sident; o <- maybeSemi; return $ ImportDecl k s o}

block = do{ l <- op "{"; x <- inBlock; r <- op "}"; return $ Block l x r }

inBlock = try(do{ lookAhead( op "}"); return [] })
      <|> try(do{ b <- block; return [b] })
      <|> try(do{ x <- importDecl; i <- inBlock; return $ [x]++ i})
      <|> try(do{ x <- anytok; i <- inBlock; return $ [(Tok x)] ++ i})

-- State functions
initSlt :: AsState
initSlt = [Map.empty] -- this is the global state, Map Definition DefInfo

parseTokens :: String -> [Token] -> Either ParseError Ast
parseTokens filename ts = runParser program initSlt filename ts
